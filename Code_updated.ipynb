{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a383930",
   "metadata": {},
   "source": [
    "# FRE6711 Quantitative Portfolio Management Memo for the Final Project\n",
    "\n",
    "This project aims 1) to build a factor-based model allocation namely a Long/Short Global Macro Strategy with a Target Beta and 2) to evaluate its sensitivity to variations of Beta and its sensitivity to the length of the estimators for covariance matrix and the expected returns under different market scenarios.\n",
    "\n",
    "#### Please run the code of Part 1 - Part 5.1 directly. Then, set the target backtesting periods in the 1st cell of Part 5.2, and run all of the rest of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import itertools\n",
    "import statsmodels.api as sm # for linear regresion\n",
    "from cvxopt import spmatrix\n",
    "from cvxopt import matrix\n",
    "from cvxopt.solvers import qp\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "sns.set() \n",
    "%matplotlib inline     \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764daac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (24, 12),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize': 'x-large',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "plt.rcParams.update(params) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96b66d",
   "metadata": {},
   "source": [
    "## Part 1: Import & Process Data \n",
    "\n",
    "## Part 1-1 Import Data\n",
    "- We fetch data from the websites and save it as csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?export=download&id=1zYT4qlPzdNb4c4b4cFBaFzHxZCXdIIGt'\n",
    "adjclose = pd.read_csv(url, parse_dates=['Date'], index_col = 'Date', dayfirst = True)\n",
    "logReturn = np.log(adjclose).diff().dropna()\n",
    "logReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?export=download&id=13cB_WCvBqF3b9r8fXl3ar0LEHwDW5QeR'\n",
    "factors = pd.read_csv(url, index_col = 0)\n",
    "factors.index = pd.to_datetime(factors.index, format = '%Y%m%d')\n",
    "factors = factors.iloc[1:-1,:]\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b9495",
   "metadata": {},
   "source": [
    "## Part 2: Build French Fama 3-factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FF3_Reg(logReturn, factors):\n",
    "    \n",
    "    excess_logReturn = logReturn.values - factors['RF'].values.reshape(len(factors['RF']),1)\n",
    "    \n",
    "    reg = pd.DataFrame(index = logReturn.index, columns = logReturn.columns)\n",
    "    for i in range(len(logReturn.columns)):\n",
    "        x = factors[[\"Mkt-RF\", \"SMB\", \"HML\"]]\n",
    "        y = excess_logReturn[:,i]\n",
    "        x = sm.add_constant(x)\n",
    "        model = sm.OLS(y, x)\n",
    "        olsres = model.fit()\n",
    "        reg.iloc[:,i] = olsres.predict(x) + factors['RF']\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b13c0",
   "metadata": {},
   "source": [
    "## Part 3: Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87433d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Optimization(logReturn, factors, w_previous, today, days_return, days_cov):\n",
    "    n = len(logReturn.columns)\n",
    "    today_idx = logReturn.index.get_indexer([today])[0]\n",
    "    df_expRet = FF3_Reg(logReturn.iloc[today_idx-days_cov:today_idx, :], factors.iloc[today_idx-days_cov:today_idx, :])\n",
    "    P = matrix(np.cov(df_expRet.T))\n",
    "    df_expRet = FF3_Reg(logReturn.iloc[today_idx-days_return:today_idx, :], factors.iloc[today_idx-days_return:today_idx, :])\n",
    "    q = matrix(-np.sum(df_expRet, axis = 0)- w_previous@P) # considering the weights of the last period\n",
    "\n",
    "    G1 = matrix(0.0, (n,n))\n",
    "    G1[::n+1] = 1.0\n",
    "    G = matrix([G1, -G1])\n",
    "    h = matrix(2.0, (n*2,1))\n",
    "\n",
    "    beta_matrix = []\n",
    "    for i in range(len(logReturn.columns)):\n",
    "        beta_matrix.append(np.cov(df_expRet.iloc[:,i], logReturn['SPY'][today_idx-days_return:today_idx])[1,0])\n",
    "\n",
    "    beta_matrix = matrix(np.array(beta_matrix)/ np.var(logReturn['SPY'][today_idx-days_return:today_idx], ddof=1))\n",
    "    A1 = matrix(1.0, (1,n))\n",
    "    A = matrix([beta_matrix.T, A1])\n",
    "    b = matrix([Beta_target, 1.0])\n",
    "    w = qp(P, q, G, h, A, b)['x']\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906378f",
   "metadata": {},
   "source": [
    "## Part 4: Output Weight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_return period could be 20, 80, 140\n",
    "days_return_L = [20, 80, 140]\n",
    "days_cov_L = [20, 80, 140]\n",
    "\n",
    "# Beta_target could be -1, -0.5, 0, 0.5, 1, 1.5\n",
    "Beta_target_L = [-1, 0, 1]\n",
    "\n",
    "weight_df = pd.DataFrame(columns = ['return days', 'cov days', 'Beta', 'Start Date'] + logReturn.columns.tolist())\n",
    "\n",
    "for days_return, days_cov, Beta_target in itertools.product(days_return_L, days_cov_L, Beta_target_L):\n",
    "    print('return days: ', days_return, 'cov days: ', days_cov, 'Beta: ', Beta_target)\n",
    "    day_pass = days_return if days_return > days_cov else days_cov\n",
    "    dates = pd.DataFrame(logReturn.index)\n",
    "    dates = dates.iloc[day_pass+1:,:]\n",
    "    g = dates.groupby(pd.Grouper(key='Date', freq='W'))  # frequency = weekly\n",
    "    dates = [group.iloc[0,0] for _,group in g]\n",
    "\n",
    "    n = len(logReturn.columns)\n",
    "    w_previous = np.ones(n)/n\n",
    "    for today in dates: \n",
    "        w = Optimization(logReturn, factors, w_previous, today, days_return, days_cov)\n",
    "        weight_df = weight_df.append({'return days':days_return, 'cov days': days_cov, 'Beta': Beta_target, 'Start Date': today}, ignore_index=True)\n",
    "        weight_df.iloc[-1,4:] = pd.Series(w).values\n",
    "        w_previous = weight_df.iloc[-1,4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb655be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark = pd.DataFrame(columns = ['return days', 'cov days', 'Beta', 'Start Date']+ logReturn.columns.tolist())\n",
    "df_benchmark['Start Date'] = logReturn.index\n",
    "df_benchmark.loc[:,['return days', 'cov days', 'Beta']] = 'SPY'\n",
    "df_benchmark['SPY'] = 1\n",
    "df_benchmark.fillna(0, inplace = True)\n",
    "weight_df = pd.concat([weight_df, df_benchmark], axis = 0)\n",
    "weight_df = weight_df.set_index(['return days' , 'cov days', 'Beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d837f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee76fd66",
   "metadata": {},
   "source": [
    "## Part 5-1: Backtesting Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2da026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BacktestingDaily(df_returns, df_weights): \n",
    "    df_weights = df_weights.set_index(df_weights.iloc[:,0])\n",
    "    df_weights.drop(columns = df_weights.columns[0], axis=1, inplace=True)\n",
    "    \n",
    "    daily_weights = pd.DataFrame(index = df_returns.index)\n",
    "    daily_weights = pd.concat([daily_weights, df_weights], axis= 1)\n",
    "    daily_weights.fillna(method=\"ffill\", inplace = True) # fill the weights to the following cells with no datum\n",
    "    returns = np.sum(df_returns * daily_weights, axis = 1)\n",
    "    PV = (returns+1).cumprod() \n",
    "    \n",
    "    daily_report = pd.DataFrame({'PV': PV, 'Daily Returns': returns})\n",
    "    daily_report.iloc[0,1] =  daily_report.iloc[0,0] - 1 \n",
    "    return daily_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40036dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvar_parametric(portofolioReturns, portfolioStd, alpha=5, dof=6):\n",
    "    # Reference Website: Jonathon Emerick, QuantPy website\n",
    "    # https://quantpy.com.au/risk-management/value-at-risk-var-and-conditional-var-cvar/\n",
    "    CVaR = portofolioReturns - norm.pdf(norm.ppf(alpha/100)) * portfolioStd / (alpha/100) \n",
    "    return CVaR\n",
    "        \n",
    "def modified_VaR(returns_mean, sigma, skew, kurt, alpha=5):\n",
    "    z_score = norm.ppf(alpha/100)\n",
    "    Z = z_score + (z_score ** 2 - 1) * skew / 6 + (z_score ** 3 - 3 * z_score) * kurt / 24 - (2 * z_score ** 3 - 5 * z_score) * skew ** 2 / 36\n",
    "    return returns_mean + (sigma * Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870572ff",
   "metadata": {},
   "source": [
    "## Part 5-2: Backtesting \n",
    "Please set the period in the following 1st section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into three periods\n",
    "#    - Before Crisis (bc): 2007/1/1 - 2008/1/1\n",
    "#    - During Crisis (dc): 2008/1/1 - 2011/1/1\n",
    "#    - After Crisis (ac): 2011/1/1 - 2022/9/30\n",
    "period_start = \"2008/1/1\"\n",
    "period_end = \"2011/1/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c174f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weight_df.loc[(weight_df['Start Date'] >= period_start) & (weight_df['Start Date'] <= period_end),:]\n",
    "LogReturn = logReturn.loc[(logReturn.index >= period_start) & (logReturn.index <= period_end),:]\n",
    "g = weights.groupby(level=[0,1,2])  \n",
    "dfList = [group for _,group in g]\n",
    "\n",
    "c = ['Cumulated PnL', 'Daily Arithmetic Mean Return', 'Daily Geometric Mean Return', 'Daily Min Return',\n",
    "        'Max 10 days Drawdown', 'Volatility', 'Sharpe Ratio', 'Skewness', 'Kurtosis', 'Modified VaR', 'CVaR']\n",
    "report = pd.DataFrame(index = weights.index.unique(), columns = c) # Create Summary Report\n",
    "PVPlot = pd.DataFrame(index = weights.index.unique()).T # DataFrame for ploting the cummulated daily PnL\n",
    "dailyReturnPlot = pd.DataFrame(index = weights.index.unique()).T  # DataFrame for ploting the distribution of daily return\n",
    "for i in range(len(dfList)):\n",
    "        w = dfList[i]\n",
    "        r = LogReturn\n",
    "        DailyReport= BacktestingDaily(r, dfList[i])\n",
    "        rep = AnnulizedAnalysis(DailyReport)\n",
    "        report.iloc[i,:] = rep.iloc[0,:]\n",
    "        PVPlot.iloc[:,i] = DailyReport['PV'] * 100\n",
    "        dailyReturnPlot.iloc[:,i] = DailyReport['Daily Returns'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728dbbd",
   "metadata": {},
   "source": [
    "### Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e4d768",
   "metadata": {},
   "source": [
    "### Cummulated Daily PnL Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecb54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_SPY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b06b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_SPY == True:\n",
    "    PVPlot.iloc[:,:].plot(grid = True, ylabel = \"Cumulative PnL\")\n",
    "else:\n",
    "    PVPlot.iloc[:,:-1].plot(grid = True, ylabel = \"Cumulative PnL\")\n",
    "\n",
    "plt.legend(loc = \"best\")\n",
    "plt.legend(bbox_to_anchor = (0,0,1.15,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2925482",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVPlot_SPY = PVPlot.loc[:,'SPY']\n",
    "PVPlot2 = PVPlot.drop(columns=['SPY'])\n",
    "col_List = [('return days','cov days', 'Beta'), ('return days', 'Beta','cov days'),('cov days', 'Beta','return days')]\n",
    "for _, element in enumerate(col_List):\n",
    "    PVPlot_temp2 = copy.deepcopy(PVPlot2)\n",
    "    PVPlot_temp2 = PVPlot_temp2.T\n",
    "    PVPlot_temp2.reset_index(inplace = True)\n",
    "    PVPlot_temp2 = pd.melt(PVPlot_temp2,id_vars=['return days','cov days', 'Beta'])\n",
    "    \n",
    "    if add_SPY == True:\n",
    "        PVPlot_temp = pd.DataFrame(columns=PVPlot2.columns).T.reset_index()\n",
    "        PVPlot_temp[element[2]] = 'SPY'\n",
    "        PVPlot_temp.drop(PVPlot_temp.tail(1).index,inplace=True)\n",
    "        PVPlot_temp = PVPlot_temp.set_index(['return days' , 'cov days', 'Beta'])\n",
    "        PVPlot_temp = pd.DataFrame(index = PVPlot2.index, columns = PVPlot_temp.index.unique())\n",
    "        PVPlot_temp.iloc[:,:] = PVPlot_SPY\n",
    "        PVPlot_temp = PVPlot_temp.T\n",
    "        PVPlot_temp.reset_index(inplace = True)\n",
    "        PVPlot_temp = pd.melt(PVPlot_temp,id_vars=['return days','cov days', 'Beta'])\n",
    "    \n",
    "        PVPlot_temp = pd.concat([PVPlot_temp, PVPlot_temp2], axis = 0).reset_index(drop=True)\n",
    "        pd.to_datetime(PVPlot_temp['Date'], format = '%Y-%m-%d')\n",
    "        distribution = sns.FacetGrid(PVPlot_temp, col =element[0] , row = element[1], hue = element[2], height = 5)\n",
    "    else:\n",
    "        distribution = sns.FacetGrid(PVPlot_temp2, col =element[0] , row = element[1], hue = element[2], height = 5)\n",
    "    distribution.map_dataframe(sns.lineplot,'Date', 'value', alpha = .7)\n",
    "    distribution.add_legend()\n",
    "    distribution.set_axis_labels('Date', 'value')\n",
    "    distribution.axes[0,0].xaxis.set_major_locator(mdates.YearLocator(base = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e12d8",
   "metadata": {},
   "source": [
    "### Daily Return Distribution Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_SPY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyReturnPlot1 = copy.deepcopy(dailyReturnPlot)\n",
    "dailyReturnPlot1.columns = dailyReturnPlot1.columns.to_flat_index()\n",
    "if add_SPY == True:\n",
    "    ax = sns.kdeplot(data=dailyReturnPlot1.iloc[:,:])\n",
    "else:\n",
    "    ax = sns.kdeplot(data=dailyReturnPlot1.iloc[:,:-1])\n",
    "sns.move_legend(ax, loc = 'best', bbox_to_anchor = (0,0,1.15,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21656754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dailyReturnPlot_SPY = dailyReturnPlot.loc[:,'SPY']\n",
    "dailyReturnPlot2 = dailyReturnPlot.drop(columns=['SPY'])\n",
    "col_List = [('return days','cov days', 'Beta'), ('return days', 'Beta','cov days'),('cov days', 'Beta','return days')]\n",
    "for _, element in enumerate(col_List):\n",
    "    dailyReturnPlot_temp2 = copy.deepcopy(dailyReturnPlot2)\n",
    "    dailyReturnPlot_temp2 = dailyReturnPlot_temp2.T\n",
    "    dailyReturnPlot_temp2.reset_index(inplace = True)\n",
    "    dailyReturnPlot_temp2 = pd.melt(dailyReturnPlot_temp2,id_vars=['return days','cov days', 'Beta'])  \n",
    "    if add_SPY == True:\n",
    "        dailyReturnPlot_temp = pd.DataFrame(columns=dailyReturnPlot2.columns).T.reset_index()\n",
    "        dailyReturnPlot_temp[element[2]] = 'SPY'\n",
    "        dailyReturnPlot_temp.drop(dailyReturnPlot_temp.tail(1).index,inplace=True)\n",
    "        dailyReturnPlot_temp = dailyReturnPlot_temp.set_index(['return days' , 'cov days', 'Beta'])\n",
    "        dailyReturnPlot_temp = pd.DataFrame(index = dailyReturnPlot2.index, columns = dailyReturnPlot_temp.index.unique())\n",
    "        dailyReturnPlot_temp.iloc[:,:] = dailyReturnPlot_SPY\n",
    "        dailyReturnPlot_temp = dailyReturnPlot_temp.T\n",
    "        dailyReturnPlot_temp.reset_index(inplace = True)\n",
    "        dailyReturnPlot_temp = pd.melt(dailyReturnPlot_temp,id_vars=['return days','cov days', 'Beta'])\n",
    "\n",
    "        dailyReturnPlot_temp = pd.concat([dailyReturnPlot_temp, dailyReturnPlot_temp2], axis = 0).reset_index(drop=True)\n",
    "        pd.to_datetime(dailyReturnPlot_temp['Date'], format = '%Y-%m-%d') \n",
    "    \n",
    "        distribution = sns.FacetGrid(dailyReturnPlot_temp, col =element[0] , row = element[1], hue = element[2], height = 4)\n",
    "    else:\n",
    "        distribution = sns.FacetGrid(dailyReturnPlot_temp2, col =element[0] , row = element[1], hue = element[2], height = 4)\n",
    "    \n",
    "    distribution.map(sns.kdeplot,'value', alpha = .7)\n",
    "    distribution.add_legend()\n",
    "    distribution.set_axis_labels('value', 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a689d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
